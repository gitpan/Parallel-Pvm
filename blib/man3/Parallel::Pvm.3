.rn '' }`
''' $RCSfile$$Revision$$Date$
'''
''' $Log$
'''
.de Sh
.br
.if t .Sp
.ne 5
.PP
\fB\\$1\fR
.PP
..
.de Sp
.if t .sp .5v
.if n .sp
..
.de Ip
.br
.ie \\n(.$>=3 .ne \\$3
.el .ne 3
.IP "\\$1" \\$2
..
.de Vb
.ft CW
.nf
.ne \\$1
..
.de Ve
.ft R

.fi
..
'''
'''
'''     Set up \*(-- to give an unbreakable dash;
'''     string Tr holds user defined translation string.
'''     Bell System Logo is used as a dummy character.
'''
.tr \(*W-|\(bv\*(Tr
.ie n \{\
.ds -- \(*W-
.ds PI pi
.if (\n(.H=4u)&(1m=24u) .ds -- \(*W\h'-12u'\(*W\h'-12u'-\" diablo 10 pitch
.if (\n(.H=4u)&(1m=20u) .ds -- \(*W\h'-12u'\(*W\h'-8u'-\" diablo 12 pitch
.ds L" ""
.ds R" ""
.ds L' '
.ds R' '
'br\}
.el\{\
.ds -- \(em\|
.tr \*(Tr
.ds L" ``
.ds R" ''
.ds L' `
.ds R' '
.ds PI \(*p
'br\}
.\"	If the F register is turned on, we'll generate
.\"	index entries out stderr for the following things:
.\"		TH	Title 
.\"		SH	Header
.\"		Sh	Subsection 
.\"		Ip	Item
.\"		X<>	Xref  (embedded
.\"	Of course, you have to process the output yourself
.\"	in some meaninful fashion.
.if \nF \{
.de IX
.tm Index:\\$1\t\\n%\t"\\$2"
..
.nr % 0
.rr F
.\}
.TH PVM 1 "perl 5.003 with" "27/Aug/96" "User Contributed Perl Documentation"
.IX Title "PVM 1"
.UC
.IX Name "Parallel::Pvm - Perl extension for the Parallel Virtual Machine (PVM) Message Passing System"
.if n .hy 0
.if n .na
.ds C+ C\v'-.1v'\h'-1p'\s-2+\h'-1p'+\s0\v'.1v'\h'-1p'
.de CQ          \" put $1 in typewriter font
.ft CW
'if n "\c
'if t \\&\\$1\c
'if n \\&\\$1\c
'if n \&"
\\&\\$2 \\$3 \\$4 \\$5 \\$6 \\$7
'.ft R
..
.\" @(#)ms.acc 1.5 88/02/08 SMI; from UCB 4.2
.	\" AM - accent mark definitions
.bd B 3
.	\" fudge factors for nroff and troff
.if n \{\
.	ds #H 0
.	ds #V .8m
.	ds #F .3m
.	ds #[ \f1
.	ds #] \fP
.\}
.if t \{\
.	ds #H ((1u-(\\\\n(.fu%2u))*.13m)
.	ds #V .6m
.	ds #F 0
.	ds #[ \&
.	ds #] \&
.\}
.	\" simple accents for nroff and troff
.if n \{\
.	ds ' \&
.	ds ` \&
.	ds ^ \&
.	ds , \&
.	ds ~ ~
.	ds ? ?
.	ds ! !
.	ds /
.	ds q
.\}
.if t \{\
.	ds ' \\k:\h'-(\\n(.wu*8/10-\*(#H)'\'\h"|\\n:u"
.	ds ` \\k:\h'-(\\n(.wu*8/10-\*(#H)'\`\h'|\\n:u'
.	ds ^ \\k:\h'-(\\n(.wu*10/11-\*(#H)'^\h'|\\n:u'
.	ds , \\k:\h'-(\\n(.wu*8/10)',\h'|\\n:u'
.	ds ~ \\k:\h'-(\\n(.wu-\*(#H-.1m)'~\h'|\\n:u'
.	ds ? \s-2c\h'-\w'c'u*7/10'\u\h'\*(#H'\zi\d\s+2\h'\w'c'u*8/10'
.	ds ! \s-2\(or\s+2\h'-\w'\(or'u'\v'-.8m'.\v'.8m'
.	ds / \\k:\h'-(\\n(.wu*8/10-\*(#H)'\z\(sl\h'|\\n:u'
.	ds q o\h'-\w'o'u*8/10'\s-4\v'.4m'\z\(*i\v'-.4m'\s+4\h'\w'o'u*8/10'
.\}
.	\" troff and (daisy-wheel) nroff accents
.ds : \\k:\h'-(\\n(.wu*8/10-\*(#H+.1m+\*(#F)'\v'-\*(#V'\z.\h'.2m+\*(#F'.\h'|\\n:u'\v'\*(#V'
.ds 8 \h'\*(#H'\(*b\h'-\*(#H'
.ds v \\k:\h'-(\\n(.wu*9/10-\*(#H)'\v'-\*(#V'\*(#[\s-4v\s0\v'\*(#V'\h'|\\n:u'\*(#]
.ds _ \\k:\h'-(\\n(.wu*9/10-\*(#H+(\*(#F*2/3))'\v'-.4m'\z\(hy\v'.4m'\h'|\\n:u'
.ds . \\k:\h'-(\\n(.wu*8/10)'\v'\*(#V*4/10'\z.\v'-\*(#V*4/10'\h'|\\n:u'
.ds 3 \*(#[\v'.2m'\s-2\&3\s0\v'-.2m'\*(#]
.ds o \\k:\h'-(\\n(.wu+\w'\(de'u-\*(#H)/2u'\v'-.3n'\*(#[\z\(de\v'.3n'\h'|\\n:u'\*(#]
.ds d- \h'\*(#H'\(pd\h'-\w'~'u'\v'-.25m'\f2\(hy\fP\v'.25m'\h'-\*(#H'
.ds D- D\\k:\h'-\w'D'u'\v'-.11m'\z\(hy\v'.11m'\h'|\\n:u'
.ds th \*(#[\v'.3m'\s+1I\s-1\v'-.3m'\h'-(\w'I'u*2/3)'\s-1o\s+1\*(#]
.ds Th \*(#[\s+2I\s-2\h'-\w'I'u*3/5'\v'-.3m'o\v'.3m'\*(#]
.ds ae a\h'-(\w'a'u*4/10)'e
.ds Ae A\h'-(\w'A'u*4/10)'E
.ds oe o\h'-(\w'o'u*4/10)'e
.ds Oe O\h'-(\w'O'u*4/10)'E
.	\" corrections for vroff
.if v .ds ~ \\k:\h'-(\\n(.wu*9/10-\*(#H)'\s-2\u~\d\s+2\h'|\\n:u'
.if v .ds ^ \\k:\h'-(\\n(.wu*10/11-\*(#H)'\v'-.4m'^\v'.4m'\h'|\\n:u'
.	\" for low resolution devices (crt and lpr)
.if \n(.H>23 .if \n(.V>19 \
\{\
.	ds : e
.	ds 8 ss
.	ds v \h'-1'\o'\(aa\(ga'
.	ds _ \h'-1'^
.	ds . \h'-1'.
.	ds 3 3
.	ds o a
.	ds d- d\h'-1'\(ga
.	ds D- D\h'-1'\(hy
.	ds th \o'bp'
.	ds Th \o'LP'
.	ds ae ae
.	ds Ae AE
.	ds oe oe
.	ds Oe OE
.\}
.rm #[ #] #H #V #F C
.SH "NAME"
.IX Header "NAME"
Parallel::Pvm \- Perl extension for the Parallel Virtual Machine (PVM) Message Passing System
.SH "SYNOPSIS"
.IX Header "SYNOPSIS"
.PP
.Vb 1
\&  use Parallel::Pvm;
.Ve
.SH "DESCRIPTION"
.IX Header "DESCRIPTION"
The \fBPVM\fR message passing system 
enables a programmer to configure a group of 
(possibly heterogenous) computers connected by 
a network into a 
parallel virtual machine.  
The system was developed by 
the University of Tennessee, Oak Ridge National 
Laboratory and Emory University. 
.PP
Using PVM, applications can 
be developed which spawns parallel processes onto 
nodes in the virtual machine to perform specific tasks.  
These parallel tasks can also periodically exchange 
information using a set of message passing functions 
developed for the system.  
.PP
PVM applications have mostly been developed in the scientific 
and engineering fields.  However applications 
for real-time and client/server systems can also be developed.  
PVM simply provides a convenient way for managing 
parallel tasks and communications  
without need for \fBrexec\fR or \fBsocket\fR level programming.
.PP
As a utility, PVM enables an organisation to leverage on the computers 
already available for parallel processing.  
Parallel applications can be started during non-peak 
hours to utilise idle CPU cycles.  
Or dedicated workstation clusters connected via 
a high performance network like \fBATM\fR can be used for high 
performance computing.  
.PP
It is recommended that you read the PVM manual pages and the book
\*(L"PVM: Parallel Virtual Machine, A users's guide and tutorial 
for networked parallel computing\*(R".  Both the PVM system and the 
book can be obtained from the HTTP address http://www.epm.ornl.gov/pvm.
.PP
For the rest of 
this document we will provide a tutorial introduction to 
developing PVM applications using perl.  The interface for some 
of the PVM functions have been changed of course to give it a 
more perl-like feel.  
.PP
Remember think perl think parallel!  Good Luck!  
.Sh "Environment Variables"
.IX Subsection "Environment Variables"
After installing \s-1PVM\s0 on your computer, there are two mandatory 
environment variables that have to be set in your .login or .cshrc
files; \fB\s-1PVM_ROOT\s0\fR and \fB\s-1PVM_ARCH\s0\fR.  
\fB\s-1PVM_ROOT\s0\fR points to the base of the \fB\s-1PVM\s0\fR 
installation directory, and \fB\s-1PVM_ARCH\s0\fR specifies the architecture 
of the computer on which \fB\s-1PVM\s0\fR is running.   An example of how this can 
be set for csh is shown below,
.PP
.Vb 2
\&        setenv PVM_ROOT /usr/local/pvm3
\&        setenv PVM_ARCH `$PVM_ROOT/lib/pvmgetarch`
.Ve
.Sh "Setting up your rsh permission"
.IX Subsection "Setting up your rsh permission"
In order for \s-1PVM\s0 applications to run, \fBrsh\fR permission 
has to be enabled.  This involves creating a \fB.rhosts\fR 
file in your \fB\s-1HOME\s0\fR directory containing, for each line, the host and 
account name you wish to allow remote execution privillages.
An example \fB.rhosts\fR file to allow a \s-1PVM\s0 application to 
remotely execute on the host \fBonyx\fR and \fBprata\fR using the 
account \fBedward\fR is shown below,
.PP
.Vb 2
\&        onyx    edward
\&        prata   edward
.Ve
.Sh "Configuring your parallel virtual machine"
.IX Subsection "Configuring your parallel virtual machine"
Parallel process management and communications is handled by a set of 
distributed deamons running on each of the nodes of the 
virtual machine.  The daemon executable, \fBpvmd\fR, is started 
when a computer is added to the virtual machine.  
A computer can be added to the virtual machine either statically 
in a console program or using a \fBhostfile\fR, 
or dynamically within the application code itself.
.PP
The first method of configuring your virtual machine 
is to use the console program \fB$\s-1PVM_ROOT/\s0lib/pvm\fR.  
Run it from the command prompt.  The console program will first add the 
local host into the virtual machine and display the prompt 
	
	pvm>
.PP
To add a host, eg \fBonyx\fR, as a node in your parallel virtual machine, simply
type
.PP
.Vb 1
\&        pvm> add onyx
.Ve
To display the current virtual machine configuration type
.PP
.Vb 1
\&        pvm> conf
.Ve
which will display node information pertaining to the host name, 
host id, host architecture, relative speed and data format.  
The console program has a number of other commands which can 
be viewed by typing \fBhelp\fR.  
.PP
The second method of configuring your virtual machine is to use 
a \fBhostfile\fR.   The \fBhostfile\fR is simply an \s-1ASCII\s0 text file 
specifing the host names of the computers to be added into your 
virtual machine.  
.PP
Additional options may be also be defined 
for the nodes pertaining to the working directory, 
execution path, login name, alternative hostname etc. A simple
example of a \fBhostfile\fR is shown below. 
.PP
.Vb 4
\&        * wd=$HOME/work ep=$HOME/bin
\&        onyx
\&        prata.nsrc.nus.sg
\&        laksa ep=$HOME/perl5/bin
.Ve
In the above example \fBhostfile\fR we are adding the 
hosts \fBonyx\fR, \fBprata.nsrc.nus.sg\fR and \fBlaksa\fR into the 
virtual machine. We are also specifying the working 
directory, \fBwd\fR, in which we want our application 
to run, and the execution path, \fBep\fR, in which we want \s-1PVM\s0
to look for executables. 
.PP
The \fB*\fR in the first line 
defines a global option for all the hosts specified after it.
We can however provide an option locally to over-ride this
global option.  This is seen for the host \fBlaksa\fR where 
we have specified its execution path to be \fB$\s-1HOME/\s0perl5/bin\fR 
instead of the \fB$\s-1HOME/\s0bin\fR.  
.PP
The third method of configuring your virtual machine 
is to call the functions \fBParallel::Pvm::addhosts\fR or \fBParallel::Pvm::delhosts\fR 
within your application.  You must still start your master
\fBpvmd\fR daemon first. This can be achieved by starting 
\fBpvm\fR and typing \fBquit\fR or simply typing  
.PP
.Vb 1
\&        echo quit | pvm
.Ve
The \s-1PVM\s0 application can then be started where 
we can add the hosts \fBprata\fR and \fBlaksa\fR by calling
.PP
.Vb 1
\&        Parallel::Pvm::addhosts("prata","laksa");
.Ve
Or we can delete a host from our configuration by calling 
.PP
.Vb 1
\&        Parallel::Pvm::delhosts("laksa");
.Ve
\s-1PVM\s0 also provides a function, \fBParallel::Pvm::conf\fR, to query the configuration 
of the parallel virtual machine. An example code to check the current 
configuration is shown below.
.PP
.Vb 9
\&        ($info,@conf) = Parallel::Pvm::conf ;
\&        if ( $info == PvmOk ){
\&          foreach $node (@conf){
\&           print "host id = $node->{'hi_tid'}\en";
\&           print "host name = $node->{'hi_name'}\en";
\&           print "host architecture = $node->{'hi_arch'}\en";
\&           print "host speed = $node->{'hi_speed'}\en";
\&          }
\&        }
.Ve
.Sh "Enrolling a task into \s-1PVM\s0"
.IX Subsection "Enrolling a task into \s-1PVM\s0"
A task has to expilictly enroll into \s-1PVM\s0 
in order for it to be known by other \s-1PVM\s0 tasks.  
This can often be done by the call 
	
	\f(CW$mytid\fR = Parallel::Pvm::mytid ;
.PP
where \fB$mytid\fR is the task id, \fB\s-1TID\s0\fR, assigned by the 
\s-1PVM\s0 system to the calling process.  Note however that 
calling any \s-1PVM\s0 function in a program will also enroll it 
into the system.  
.Sh "Spawning parallel tasks"
.IX Subsection "Spawning parallel tasks"
A \s-1PVM\s0 application can spawn parallel tasks in your parallel 
virtual machine.  Assuming there is exists an executable called 
\fBclient\fR, we can spawn four \fBclient\fR tasks in our virtual 
machine by calling 
.PP
.Vb 1
\&        ($ntask,@tids) = Parallel::Pvm::spawn("client",4);
.Ve
For each of the four spawned processes, the \s-1PVM\s0 system first 
allocates a host node and looks for the executable in the 
execuation path of that host.  If the executable is found it 
is started.  
.PP
The task which called the \fBParallel::Pvm::spawn\fR is known as 
the \fBparent\fR task.  
The number of \fBchildren\fR tasks which are actually spawned by 
\fBParallel::Pvm::spawn\fR is returned in the scalar \fB$ntask\fR.  
The \fB@tids\fR array returns the task id, \fB\s-1TID\s0\fR, of the spawned 
\fBchildren\fR tasks which will be useful later for 
communicating with them.  A \fB\s-1TID\s0\fR < 0 indicates a task failure 
to spawn and can be used to determine the nature of 
the problem.  Eg.
.PP
.Vb 7
\&        foreach $tid (@tids){
\&           if ( $tid < 0 ){
\&              if ( $tid == PvmNoMem )
\&                 warn "no memory ! \en";
\&              }else if ( $tid == PvmSysErr ){
\&                 warn "pvmd not responding ! \en";
\&              } ... 
.Ve
.Vb 2
\&           }
\&        }
.Ve
For more sophisticated users, \fBParallel::Pvm::spawn\fR may be given additional 
argument parameters to control how/where you want a task to be spawned.
For example, you can specifically spawn \fBclient\fR in the internet 
host <onyx.nsrc.nus.sg> by calling
.PP
.Vb 1
\&        Parallel::Pvm::spawn("client",1,PvmTaskHost,"onyx.nsrc.nus.sg");
.Ve
Or you can spawn \fBclient\fR on host nodes only of a particular architecture, 
say \s-1RS6K\s0 workstations, by calling
.PP
.Vb 1
\&        Parallel::Pvm::spawn("client",4,PvmTaskArch,"RS6K");
.Ve
Note that tasks which have been spawned by using \fBParallel::Pvm::spawn\fR 
do not need to be explicitly enrolled into the pvm system.  
.Sh "Exchanging messages between tasks"
.IX Subsection "Exchanging messages between tasks"
Messages can be sent to a task enrolled into \s-1PVM\s0 by specifying 
the example code sequence
.PP
.Vb 4
\&        Parallel::Pvm::initsend ;
\&        Parallel::Pvm::pack(2.345,"hello dude");
\&        Parallel::Pvm::pack(1234);
\&        Parallel::Pvm::send($dtid,999);
.Ve
In our example we first call \fBParallel::Pvm::initsend\fR to initialize 
the internal \s-1PVM\s0 send buffer.  
We then call \fBParallel::Pvm::buffer\fR to fill this buffer with a double (2.345),
, a string ("hello dude"), and an integer (1234).  
Having filled the send buffer with the data that is to be sent, 
we call \fBParallel::Pvm::send\fR to do the actual send to the task identifed by the \fB\s-1TID\s0\fR 
\fB$dtid\fR.   We also label the sending message to disambiguate it with 
other messages with a tag.  This is done with the 999 argument in 
\fBParallel::Pvm::send\fR function.  
.PP
For the destination task, we can receive the message sent by 
performing a blocking receive with the function \fBParallel::Pvm::recv\fR.  
A code sequence for the above example on the recipent 
end will be 
.PP
.Vb 4
\&        if ( Parallel::Pvm::recv >= 0 ){
\&           $int_t = Parallel::Pvm::unpack ;
\&           ($double_t,$str_t) = Parallel::Pvm::unpack ;
\&        }
.Ve
Note that we must unpack the message in the reverse order in which we packed 
our message.  
In our example \fBParallel::Pvm::recv\fR will receive any message sent to it.  
In order to selectively receive a message, we could specify 
the \fB\s-1TID\s0\fR of the source task and the message \fBtag\fR.  For
example, 
.PP
.Vb 2
\&        $tag = 999;
\&        Parallel::Pvm::recv($stid,$tag) ;
.Ve
Other message passing functions that you may find useful are 
\fBParallel::Pvm::psend\fR, \fBParallel::Pvm::trecv\fR, \fBParallel::Pvm::nrecv\fR and \fBParallel::Pvm::precv\fR.  
.Sh "Parallel I/O "
.IX Subsection "Parallel I/O "
Note that the file descriptors in a parent task are not
inherented in the spawned \fBchildren\fR tasks unlike \fBfork\fR.  
By default any file I/O will be performed in the working 
directory specified in the \fBhostfile\fR if no 
absolute path was provided for the opened file.  
If no working directory is specified, the default is the 
\fB$\s-1HOME\s0\fR directory.  For directories which are not \s-1NFS\s0 mounted, 
this would mean that each task performs its own separate 
I/O.  
.PP
In the case of \fBtty\fR output, tasks which are not 
started from the command prompt will have their 
\fBstdout\fR and \fBstderr\fR directed to the file pvml.<uid>.  
This may be redirected to a \fBparent\fR task by 
calling 
.PP
.Vb 1
\&        Parallel::Pvm::catchout;
.Ve
for \fBstdout\fR or 
.PP
.Vb 1
\&        Parallel::Pvm::catchout(stderr);
.Ve
for \fBstderr\fR.   You can direct the \fBstdout\fR or \fBstderr\fR output 
of a task to another \fB\s-1TID\s0\fR , other then its parent, by calling 
.PP
.Vb 1
\&        Parallel::Pvm::setopt(PvmOutTid,$tid);
.Ve
.Sh "Incorporating fault tolerance"
.IX Subsection "Incorporating fault tolerance"
The function \fBParallel::Pvm::notify\fR can be used to incorporate some 
fault tolerance into your \s-1PVM\s0 application.  
You may use it to ask the \s-1PVM\s0 
to monitor the liveliness of a set of hosts or tasks
during the execution of a \s-1PVM\s0 application. 
For example you can instrument 
your application to monitor 3 tasks with \fB\s-1TID\s0\fR \fB$task1\fR, 
\fB$task2\fR, and \fB$task3\fR, by using the code segments 
.PP
.Vb 3
\&        @monitor = ($task1,$task2,$task3);
\&        Parallel::Pvm::notify(PvmTaskExit,999,@monitor_task);
\&        ...
.Ve
.Vb 4
\&        if ( Parallel::Pvm::probe(-1,999) ){
\&           $task = Parallel::Pvm::recv_notify ;
\&           print "Oops! task $task has failed ... \en" ; 
\&        }
.Ve
If either \fB$task1\fR, \fB$task2\fR or \fB$task3\fR 
fails,  the notification will take the form of 
a single message with the 
tag 999.  The message content will inform you of 
the \fB\s-1TID\s0\fR of the failed task.  
.PP
A similar scheme may be employed for the notification of host 
failures in your parallel virtual machine.  
.Sh "Client/Server example"
.IX Subsection "Client/Server example"
\fBClient:\fR
.PP
.Vb 3
\&        use Pvm;
\&        use File::Basename;
\&        ...
.Ve
.Vb 2
\&        # Look for server tid and assume 
\&        # server name is 'service_provider'
.Ve
.Vb 7
\&        @task_list = Parallel::Pvm::tasks ;
\&        foreach $task (@task_list){
\&           $a_out = $task->{'ti_a_out'} ;
\&           $base = basename $a_out ;
\&           if ( $base eq 'service_provider' )
\&                $serv_tid = $task->{'ti_tid'} ;
\&        }
.Ve
.Vb 4
\&        # This is just one way (not necessarily the
\&        # best) of getting a server tid.
\&        # You could do the same thing by reading 
\&        # the server tid posted in a file. 
.Ve
.Vb 4
\&        ...
\&        
\&        # send request for service
\&        Parallel::Pvm::send($serv_tid,$REQUEST);
.Ve
.Vb 4
\&        # receive service from server
\&        Parallel::Pvm::recv(-1,$RESPONSE);
\&        @service_packet = Parallel::Pvm::unpack ;
\&        ...
.Ve
\fBServer:\fR
.PP
.Vb 2
\&        while(1){
\&           ...
.Ve
.Vb 1
\&           if ( Parallel::Pvm::probe(-1,$REQUEST) ){
.Ve
.Vb 3
\&              # a service request has arrived !
\&              $bufid = Parallel::Pvm::recv ;
\&              ($info,$bytes,$tag,$stid) = Parallel::Pvm::bufinfo($bufid) ;
.Ve
.Vb 16
\&              if ( fork == 0 ){
\&                 # fork child process to handle service
\&                 ...
\& 
\&                 # provide service
\&                 Parallel::Pvm::initsend ;
\&                 Parallel::Pvm::pack(@service);
\&                 Parallel::Pvm::send($stid,$RESPONSE);
\&                 
\&                 # exit child process
\&                 exit ;
\&              }
\&           }       
\&           ...
\&        
\&        }
.Ve
.Sh "\s-1PVM\s0 groups "
.IX Subsection "\s-1PVM\s0 groups "
The \s-1PVM\s0 dynamic group functions have not been ported to perl yet.  
These functions provide facilities for collecting processes under 
a single \fBgroup\fR label, and applying aggregate operations onto 
them.  Examples of these functions are \fBParallel::Pvm::barrier\fR, \fBParallel::Pvm::reduce\fR, 
\fBParallel::Pvm::bcast\fR etc.  
One of our concerns is that these group functions may be 
changed or augmented in the future releases of \s-1PVM\s0 3.4*. A decision 
for porting the group functions will be made after 
\s-1PVM\s0 3.4 has been released.  
.SH "FUNCTIONS"
.IX Header "FUNCTIONS"
.Ip "\fBParallel::Pvm::addhosts\fR " 4
.IX Item "\fBParallel::Pvm::addhosts\fR "
Adds one or more host names to a parallel virtual machine. Eg.
.Sp
.Vb 1
\&        $info = Parallel::Pvm::addhosts(@host_list) ;
.Ve
.Ip "\fBParallel::Pvm::bufinfo\fR" 4
.IX Item "\fBParallel::Pvm::bufinfo\fR"
Returns information about the requested message buffer. Eg.
.Sp
.Vb 1
\&        ($info,$bytes,$tag,$tid) = Parallel::Pvm::bufinfo($bufid);
.Ve
.Ip "\fBParallel::Pvm::catchout\fR" 4
.IX Item "\fBParallel::Pvm::catchout\fR"
Catches output from children tasks.  Eg.
.Sp
.Vb 2
\&        # Parallel::Pvm::catchout(stdout);
\&        $bufid = Parallel::Pvm::catchout; 
.Ve
.Ip "\fBParallel::Pvm::config\fR" 4
.IX Item "\fBParallel::Pvm::config\fR"
Returns information about the present virtual machine configuration. Eg.
.Sp
.Vb 1
\&        ($info,@host_ref_list) = Parallel::Pvm::config ;
.Ve
.Ip "\fBParallel::Pvm::delhosts\fR" 4
.IX Item "\fBParallel::Pvm::delhosts\fR"
Deletes one or more hosts from the virtual machine. Eg.
.Sp
.Vb 1
\&        $info = Parallel::Pvm::delhosts(@host_list);
.Ve
.Ip "\fBParallel::Pvm::exit\fR" 4
.IX Item "\fBParallel::Pvm::exit\fR"
Tells the local \s-1PVM\s0 daemon that the process is leaving.  Eg.
.Sp
.Vb 1
\&        $info = Parallel::Pvm::exit ;
.Ve
.Ip "\fBParallel::Pvm::freebuf\fR" 4
.IX Item "\fBParallel::Pvm::freebuf\fR"
Disposes of a message buffer. Eg.
.Sp
.Vb 1
\&        $info = Parallel::Pvm::freebuf($bufid);
.Ve
.Ip "\fBParallel::Pvm::getopt\fR" 4
.IX Item "\fBParallel::Pvm::getopt\fR"
Shows various libpvm options.  Eg.
.Sp
.Vb 2
\&        $val = Parallel::Pvm::getopt(PvmOutputTid);
\&        $val = Parallel::Pvm::getopt(PvmFragSize);
.Ve
.Ip "\fBParallel::Pvm::getrbuf\fR" 4
.IX Item "\fBParallel::Pvm::getrbuf\fR"
Returns the message buffer identifier for the active receive buffer. Eg.
.Sp
.Vb 1
\&        $bufid = Parallel::Pvm::getrbuf ;
.Ve
.Ip "\fBParallel::Pvm::getsbuf\fR" 4
.IX Item "\fBParallel::Pvm::getsbuf\fR"
Returns the message buffer identifier for the active send buffer.  Eg. 
.Sp
.Vb 1
\&        $bufid = Parallel::Pvm::getsbuf ;
.Ve
.Ip "\fBParallel::Pvm::halt\fR" 4
.IX Item "\fBParallel::Pvm::halt\fR"
Shuts down the entire \s-1PVM\s0 system. Eg. 
.Sp
.Vb 1
\&        $info = Parallel::Pvm::halt ;
.Ve
.Ip "\fBParallel::Pvm::hostsync\fR" 4
.IX Item "\fBParallel::Pvm::hostsync\fR"
Gets time-of-day clock from \s-1PVM\s0 host. Eg.
.Sp
.Vb 1
\&        ($info,$remote_clk,$delta) = Parallel::Pvm::hostsync($host) ;
.Ve
where \fBdelta\fR is the time-of-day equivalent to \fBlocal_clk \- remote_clk\fR. 
.Ip "\fBParallel::Pvm::initsend\fR" 4
.IX Item "\fBParallel::Pvm::initsend\fR"
Clears default send buffer and specifies message encoding. Eg.
.Sp
.Vb 2
\&        # Parallel::Pvm::initsend(PvmDataDefault) ;
\&        $bufid = Parallel::Pvm::initsend
.Ve
.Ip "\fBParallel::Pvm::kill\fR" 4
.IX Item "\fBParallel::Pvm::kill\fR"
Terminates a specified \s-1PVM\s0 process.
.Sp
.Vb 1
\&        $info = Parallel::Pvm::kill($tid);
.Ve
.Ip "\fBParallel::Pvm::mcast\fR" 4
.IX Item "\fBParallel::Pvm::mcast\fR"
Multicast the data in the active message buffer to a set of tasks.  Eg.
.Sp
.Vb 1
\&        $info = Parallel::Pvm::mcast(@tid_list,$tag);
.Ve
.Ip "\fBParallel::Pvm::mkbuf\fR" 4
.IX Item "\fBParallel::Pvm::mkbuf\fR"
Creates a new message buffer. Eg.
.Sp
.Vb 2
\&        # Parallel::Pvm::mkbuf(PvmDataDefault);
\&        $bufid = Parallel::Pvm::mkbuf ;
.Ve
.Vb 1
\&        $bufid = Parallel::Pvm::mkbuf(PvmDataRaw);
.Ve
.Ip "\fBParallel::Pvm::mstat\fR" 4
.IX Item "\fBParallel::Pvm::mstat\fR"
Returns the status of a host in the virtual machine.  Eg. 
.Sp
.Vb 1
\&        $status = Parallel::Pvm::mstat($host);
.Ve
.Ip "\fBParallel::Pvm::mytid\fR" 4
.IX Item "\fBParallel::Pvm::mytid\fR"
Returns the tid of the calling process.
.Sp
.Vb 1
\&        $mytid = Parallel::Pvm::mytid ;
.Ve
.Ip "\fBParallel::Pvm::notify\fR" 4
.IX Item "\fBParallel::Pvm::notify\fR"
Requests notification of \s-1PVM\s0 events. Eg.
.Sp
.Vb 1
\&        $info = Parallel::Pvm::notify(PvmHostDelete,999,$host_list);
.Ve
.Ip "\fBParallel::Pvm::nrecv\fR" 4
.IX Item "\fBParallel::Pvm::nrecv\fR"
Nonblocking receive.  Eg.
.Sp
.Vb 2
\&        # Parallel::Pvm::nrecv(-1,-1);
\&        $bufid = Parallel::Pvm::nrecv ;
.Ve
.Vb 2
\&        # Parallel::Pvm::nrecv($tid,-1);
\&        $bufid = Parallel::Pvm::nrecv($tid) ;
.Ve
.Vb 1
\&        $bufid = Parallel::Pvm::nrecv($tid,$tag) ;
.Ve
.Ip "\fBParallel::Pvm::pack\fR" 4
.IX Item "\fBParallel::Pvm::pack\fR"
Packs active message buffer with data. Eg.
.Sp
.Vb 1
\&        $info = Parallel::Pvm::pack(@data_list);
.Ve
.Ip "\fBParallel::Pvm::parent\fR" 4
.IX Item "\fBParallel::Pvm::parent\fR"
Returns the tid of the process that spawned the calling process.  Eg.
.Sp
.Vb 1
\&        $tid = Parallel::Pvm::parent ;
.Ve
.Ip "\fBParallel::Pvm::perror\fR" 4
.IX Item "\fBParallel::Pvm::perror\fR"
Prints the error status of the las \s-1PVM\s0 call.
.Sp
.Vb 1
\&        $info = Parallel::Pvm::perror($msg);
.Ve
.Ip "\fBParallel::Pvm::precv\fR" 4
.IX Item "\fBParallel::Pvm::precv\fR"
Receives a message directly into a buffer.  
.Sp
.Vb 2
\&        # Parallel::Pvm::precv(-1,-1);
\&        @recv_buffer = Parallel::Pvm::precv ;
.Ve
.Vb 2
\&        # Parallel::Pvm::precv($tid,-1);
\&        @recv_buffer = Parallel::Pvm::precv($tid);
.Ve
.Vb 1
\&        @recv_buffer = Parallel::Pvm::precv($tid,$tag);
.Ve
Note that the current limit for the receive buffer is 100 KBytes.  
.Ip "\fBParallel::Pvm::probe\fR" 4
.IX Item "\fBParallel::Pvm::probe\fR"
Checks whether a message has arrived.  Eg.
.Sp
.Vb 2
\&        # Parallel::Pvm::probe(-1,-1);
\&        $bufid = Parallel::Pvm::probe ;
.Ve
.Vb 2
\&        # Parallel::Pvm::probe($tid,-1);
\&        $bufid = Parallel::Pvm::probe($tid);
.Ve
.Vb 1
\&        $bufid = Parallel::Pvm::probe($tid,$tag);
.Ve
.Ip "\fBParallel::Pvm::psend\fR" 4
.IX Item "\fBParallel::Pvm::psend\fR"
Packs and sends data in one call.  Eg.
.Sp
.Vb 1
\&        $info = Parallel::Pvm::psend($tid,$tag,@send_buffer);
.Ve
.Ip "\fBParallel::Pvm::pstat\fR" 4
.IX Item "\fBParallel::Pvm::pstat\fR"
Returns the status of the specified \s-1PVM\s0 process.  Eg.
.Sp
.Vb 1
\&        $status = Parallel::Pvm::pstat($tid);
.Ve
.Ip "\fBParallel::Pvm::recv\fR" 4
.IX Item "\fBParallel::Pvm::recv\fR"
Receives a message.  Eg.
.Sp
.Vb 2
\&        # Parallel::Pvm::recv(-1,-1);
\&        $bufid = Parallel::Pvm::recv ;
.Ve
.Vb 2
\&        # Parallel::Pvm::recv($tid,-1);
\&        $bufid = Parallel::Pvm::recv($tid) ;
.Ve
.Vb 1
\&        $bufid = Parallel::Pvm::recv($tid,$tag);
.Ve
.Ip "\fBParallel::Pvm::recvf\fR" 4
.IX Item "\fBParallel::Pvm::recvf\fR"
Redefines the comparison function used to accept messages.  Eg.
.Sp
.Vb 1
\&        Parallel::Pvm::recvf(\e&new_foo);
.Ve
.Ip "\fBParallel::Pvm::recv_notify\fR" 4
.IX Item "\fBParallel::Pvm::recv_notify\fR"
Receives the notification message initiated by \fBParallel::Pvm::notify\fR.  This 
should be preceded by a \fBParallel::Pvm::probe\fR.  Eg.
.Sp
.Vb 3
\&        if ( Parallel::Pvm::probe(-1,$notify_tag) ){
\&                $message = Parallel::Pvm::recv_notify ;
\&        }
.Ve
.Ip "\fBParallel::Pvm::recvf_old\fR" 4
.IX Item "\fBParallel::Pvm::recvf_old\fR"
Resets the comparison function for accepting messages to the 
previous method before a call to \fBParallel::Pvm::recf\fR.  
.Ip "\fBParallel::Pvm::reg_hoster\fR" 4
.IX Item "\fBParallel::Pvm::reg_hoster\fR"
Registers this task as responsible for adding new \s-1PVM\s0 hosts.  Eg.
.Sp
.Vb 1
\&        $info = Parallel::Pvm::reg_hoster ;
.Ve
.Ip "\fBParallel::Pvm::reg_rm\fR" 4
.IX Item "\fBParallel::Pvm::reg_rm\fR"
Registers this task as a \s-1PVM\s0 resource manager.  Eg.
.Sp
.Vb 1
\&        $info = Parallel::Pvm::reg_rm ;
.Ve
.Ip "\fBParallel::Pvm::reg_tasker\fR" 4
.IX Item "\fBParallel::Pvm::reg_tasker\fR"
Registers this task as responsible for starting new \s-1PVM\s0 tasks.  Eg.
.Sp
.Vb 1
\&        $info = Parallel::Pvm::reg_tasker ;
.Ve
.Ip "\fBParallel::Pvm::send\fR" 4
.IX Item "\fBParallel::Pvm::send\fR"
Send the data in the active message buffer.  Eg.  
.Sp
.Vb 2
\&        # Parallel::Pvm::send(-1,-1);
\&        $info = Parallel::Pvm::send ;
.Ve
.Vb 2
\&        # Parallel::Pvm::send($tid,-1);
\&        $info = Parallel::Pvm::send($tid);
.Ve
.Vb 1
\&        $info = Parallel::Pvm::send($tid,$tag);
.Ve
.Ip "\fBParallel::Pvm::sendsig\fR" 4
.IX Item "\fBParallel::Pvm::sendsig\fR"
Sends a signal to another \s-1PVM\s0 process.  Eg.
.Sp
.Vb 2
\&        use POSIX qw(:signal_h);
\&        ...
.Ve
.Vb 1
\&        $info = Parallel::Pvm::sendsig($tid,SIGKILL);
.Ve
.Ip "\fBParallel::Pvm::setopt\fR" 4
.IX Item "\fBParallel::Pvm::setopt\fR"
Sets various libpvm options.  Eg.
.Sp
.Vb 1
\&        $oldval=Parallel::Pvm::setopt(PvmOutputTid,$val);
.Ve
.Vb 1
\&        $oldval=Parallel::Pvm::setopt(PvmRoute,PvmRouteDirect);
.Ve
.Ip "\fBParallel::Pvm::setrbuf\fR " 4
.IX Item "\fBParallel::Pvm::setrbuf\fR "
Switches the active receive buffer and saves the previous buffer.  Eg.
.Sp
.Vb 1
\&        $oldbuf = Parallel::Pvm::setrbuf($bufid);
.Ve
.Ip "\fBParallel::Pvm::setsbuf\fR" 4
.IX Item "\fBParallel::Pvm::setsbuf\fR"
Switches the active send buffer.  Eg.
.Sp
.Vb 1
\&        $oldbuf = Parallel::Pvm::setsbuf($bufid);
.Ve
.Ip "\fBParallel::Pvm::spawn\fR" 4
.IX Item "\fBParallel::Pvm::spawn\fR"
Starts new \s-1PVM\s0 processes.  Eg.
.Sp
.Vb 2
\&        # Parallel::Pvm::spawn("compute.pl",4,PvmTaskDefault,"");
\&        ($ntask,@tid_list) = Parallel::Pvm::spawn("compute.pl",4);
.Ve
.Vb 1
\&        ($ntask,@tid_list) = Parallel::Pvm::spawn("compute.pl",4,PvmTaskHost,"onyx");
.Ve
.Ip "\fBParallel::Pvm::tasks\fR" 4
.IX Item "\fBParallel::Pvm::tasks\fR"
Returns information about the tasks running on the virtual machine. Eg.
.Sp
.Vb 2
\&        # Parallel::Pvm::tasks(0); Returns all tasks
\&        ($info,@task_list) = Parallel::Pvm::tasks ;
.Ve
.Vb 3
\&        # Returns only for task $tid 
\&        ($info,@task_list) = Parallel::Pvm::tasks($tid) ;
\&        
.Ve
.Ip "\fBParallel::Pvm::tidtohost\fR" 4
.IX Item "\fBParallel::Pvm::tidtohost\fR"
Returns the host \s-1ID\s0 on which the specified task is running.  Eg.
.Sp
.Vb 1
\&        $dtid = Parallel::Pvm::tidtohost($tid);
.Ve
.Ip "\fBParallel::Pvm::trecv\fR" 4
.IX Item "\fBParallel::Pvm::trecv\fR"
Receive with timeout.  Eg.
.Sp
.Vb 2
\&        # Parallel::Pvm::trecv(-1,-1,1,0); time out after 1 sec
\&        $bufid = Parallel::Pvm::trecv ;
.Ve
.Vb 2
\&        # time out after 2*1000000 + 5000 usec  
\&        $bufid = Parallel::Pvm::trecv($tid,$tag,2,5000);
.Ve
.Ip "\fBParallel::Pvm::unpack\fR" 4
.IX Item "\fBParallel::Pvm::unpack\fR"
Unpacks the active receive message buffer.  Eg.
.Sp
.Vb 1
\&        @recv_buffer = Parallel::Pvm::unpack ;
.Ve
.SH "AUTHOR"
.IX Header "AUTHOR"
Edward Walker, edward@nsrc.nus.sg,
National Supercomputing Research Centre, Singapore
.SH "SEE ALSO"
.IX Header "SEE ALSO"
\fIperl\fR\|(1), \fIpvm_intro\fR\|(1PVM)

.rn }` ''
